{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e36281f-bcc3-41d9-83b3-ad77ee5434c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Scrape scripts to get data from Ourlads and ESPN\n",
    "\n",
    "## Set up the environments to enable Selenium to run on Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d945b24-d6a6-4901-90ba-177dda8e40be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1045 bytes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks/scripts/selenium-install.sh</td><td>selenium-install.sh</td><td>1045</td><td>1726529872000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks/scripts/selenium-install.sh",
         "selenium-install.sh",
         1045,
         1726529872000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.mkdirs(\"dbfs:/databricks/scripts/\")\n",
    "dbutils.fs.put(\"/databricks/scripts/selenium-install.sh\",\"\"\"\n",
    "#!/bin/bash\n",
    "%sh\n",
    "LAST_VERSION=\"https://www.googleapis.com/download/storage/v1/b/chromium-browser-snapshots/o/Linux_x64%2FLAST_CHANGE?alt=media\"\n",
    "VERSION=$(curl -s -S $LAST_VERSION)\n",
    "if [ -d $VERSION ] ; then\n",
    "  echo \"version already installed\"\n",
    "  exit\n",
    "fi\n",
    " \n",
    "rm -rf /tmp/chrome/$VERSION\n",
    "mkdir -p /tmp/chrome/$VERSION\n",
    " \n",
    "URL=\"https://www.googleapis.com/download/storage/v1/b/chromium-browser-snapshots/o/Linux_x64%2F$VERSION%2Fchrome-linux.zip?alt=media\"\n",
    "ZIP=\"${VERSION}-chrome-linux.zip\"\n",
    " \n",
    "curl -# $URL > /tmp/chrome/$ZIP\n",
    "unzip /tmp/chrome/$ZIP -d /tmp/chrome/$VERSION\n",
    " \n",
    "URL=\"https://www.googleapis.com/download/storage/v1/b/chromium-browser-snapshots/o/Linux_x64%2F$VERSION%2Fchromedriver_linux64.zip?alt=media\"\n",
    "ZIP=\"${VERSION}-chromedriver_linux64.zip\"\n",
    " \n",
    "curl -# $URL > /tmp/chrome/$ZIP\n",
    "unzip /tmp/chrome/$ZIP -d /tmp/chrome/$VERSION\n",
    " \n",
    "mkdir -p /tmp/chrome/chrome-user-data-dir\n",
    " \n",
    "rm -f /tmp/chrome/latest\n",
    "ln -s /tmp/chrome/$VERSION /tmp/chrome/latest\n",
    " \n",
    "# to avoid errors about missing libraries\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y libgbm-dev\n",
    "\"\"\", True)\n",
    "display(dbutils.fs.ls(\"dbfs:/databricks/scripts/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd52174-2f49-4daf-a030-79f62f43f724",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dbfs/databricks/scripts/selenium-install.sh: line 3: fg: no job control\n",
      "\r",
      "                                                                           0.0%\r",
      "#                                                                          2.2%\r",
      "######                                                                     8.5%\r",
      "######                                                                     9.0%\r",
      "##########                                                                14.2%\r",
      "#############                                                             18.4%\r",
      "#################                                                         24.0%\r",
      "####################                                                      28.4%\r",
      "#######################                                                   32.2%\r",
      "############################                                              39.2%\r",
      "##################################                                        48.4%\r",
      "######################################                                    53.4%\r",
      "###########################################                               60.4%\r",
      "#################################################                         69.4%\r",
      "#########################################################                 79.2%\r",
      "##############################################################            87.2%\r",
      "####################################################################      95.7%\r",
      "######################################################################## 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/chrome/1356175-chrome-linux.zip\n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/MEIPreload/manifest.json  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/MEIPreload/preloaded_data.pb  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/PrivacySandboxAttestationsPreloaded/manifest.json  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/PrivacySandboxAttestationsPreloaded/privacy-sandbox-attestations.dat  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/chrome  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/chrome-wrapper  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/chrome_100_percent.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/chrome_200_percent.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/chrome_crashpad_handler  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/chrome_sandbox  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/icudtl.dat  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/libEGL.so  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/libGLESv2.so  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/libvk_swiftshader.so  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/libvulkan.so.1  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/product_logo_48.png  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/resources.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/v8_context_snapshot.bin  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/vk_swiftshader_icd.json  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/xdg-mime  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/xdg-settings  \n",
      "   creating: /tmp/chrome/1356175/chrome-linux/locales/\n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/lv.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/gu.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/pl.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/en-US.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/el.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ms.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ru.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sr.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/nl.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/id.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/en-GB.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/vi.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/mr.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/tr.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ms.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/pl.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/bg.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sw.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/en-GB.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/id.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sl.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/bg.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/hi.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ar.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sk.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fr.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ml.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fi.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ro.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/zh-CN.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/it.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/el.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ja.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fil.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fi.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ar-XB.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ta.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/pt-BR.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/kn.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ro.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/lv.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/hr.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/zh-TW.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/es-419.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sv.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ur.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ja.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/uk.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/pt-PT.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ml.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/he.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fa.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ca.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/hu.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/bn.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fil.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sv.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/cs.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/de.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/de.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ru.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fr.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/gu.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/fa.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/th.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ca.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sl.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/cs.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/nb.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/en-US.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sw.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/et.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/he.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ko.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/pt-PT.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/en-XA.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ar.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/it.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/te.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/uk.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/zh-TW.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/af.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/hu.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ko.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/mr.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/kn.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sr.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/te.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ar-XB.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/lt.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/lt.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/tr.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/zh-CN.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/pt-BR.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/hr.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/es.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/nb.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/am.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/et.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/es.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/hi.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/th.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/vi.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ur.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/am.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/da.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/ta.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/sk.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/bn.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/en-XA.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/da.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/nl.pak  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/es-419.pak.info  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/locales/af.pak  \n",
      "   creating: /tmp/chrome/1356175/chrome-linux/resources/\n",
      "   creating: /tmp/chrome/1356175/chrome-linux/resources/inspector_overlay/\n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/resources/inspector_overlay/main.js  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/resources/inspector_overlay/inspector_overlay_resources.grd  \n",
      "   creating: /tmp/chrome/1356175/chrome-linux/resources/accessibility/\n",
      "   creating: /tmp/chrome/1356175/chrome-linux/resources/accessibility/reading_mode_gdocs_helper/\n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/resources/accessibility/reading_mode_gdocs_helper/gdocs_script.js  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/resources/accessibility/reading_mode_gdocs_helper/content.js  \n",
      "  inflating: /tmp/chrome/1356175/chrome-linux/resources/accessibility/reading_mode_gdocs_helper_manifest.json  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#=#=#                                                                         \r",
      "##O#-#                                                                        \r",
      "\r",
      "########                                                                  11.6%\r",
      "##############################                                            42.7%\r",
      "######################################################################## 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/chrome/1356175-chromedriver_linux64.zip\n",
      "  inflating: /tmp/chrome/1356175/chromedriver_linux64/LICENSE.chromedriver  \n",
      "  inflating: /tmp/chrome/1356175/chromedriver_linux64/chromedriver  \n",
      "Get:1 https://repos.azul.com/zulu/deb stable InRelease [5,289 B]\n",
      "Get:2 https://repos.azul.com/zulu/deb stable/main amd64 Packages [342 kB]\n",
      "Get:3 https://repos.azul.com/zulu/deb stable/main arm64 Packages [198 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,267 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,030 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1,792 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,585 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,150 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,439 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,181 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
      "Fetched 34.8 MB in 5s (6,732 kB/s)\n",
      "Reading package lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: https://repos.azul.com/zulu/deb/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  libgbm-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 70 not upgraded.\n",
      "Need to get 9,546 B of archives.\n",
      "After this operation, 100 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgbm-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [9,546 B]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debconf: delaying package configuration, since apt-utils is not installed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 9,546 B in 0s (27.7 kB/s)\n",
      "Selecting previously unselected package libgbm-dev:amd64.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 106459 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libgbm-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\r\n",
      "Unpacking libgbm-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\r\n",
      "Setting up libgbm-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\r\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "/dbfs/databricks/scripts/selenium-install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7d7490b-dd7d-4e42-95dc-e58df629139d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fake_useragent\n",
      "  Obtaining dependency information for fake_useragent from https://files.pythonhosted.org/packages/e4/99/60d8cf1b26938c2e0a57e232f7f15641dfcd6f8deda454d73e4145910ff6/fake_useragent-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/b3/38/5aac23e57d61707f91914506902e621632de8dc56b60446459901469b9e2/selenium-4.24.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.24.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /databricks/python3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/1c/70/efa56ce2271c44a7f4f43533a0477e6854a0948e9f7b76491de1fd3be7c9/trio-0.26.2-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /databricks/python3/lib/python3.11/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /databricks/python3/lib/python3.11/site-packages (from selenium) (4.10.0)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Obtaining dependency information for websocket-client~=1.8 from https://files.pythonhosted.org/packages/5a/84/44687a29792a70e111c5c477230a72c4b957d88d16141199bf9acb7537a3/websocket_client-1.8.0-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for attrs>=23.2.0 from https://files.pythonhosted.org/packages/6a/21/5b6702a7f963e95456c0de2d495f67bf5fd62840ac655dc451586d23d39a/attrs-24.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sortedcontainers from https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in /databricks/python3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sniffio>=1.3.0 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Obtaining dependency information for PySocks!=1.5.7,<2.0,>=1.5.6 from https://files.pythonhosted.org/packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl.metadata\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /databricks/python3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
      "Downloading selenium-4.24.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/9.6 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m7.0/9.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/476.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, fake_useragent, wsproto, websocket-client, sniffio, PySocks, attrs, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 0.58.0\n",
      "    Not uninstalling websocket-client at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b6770f8f-39f9-4a94-982d-ac5eecc2fd66\n",
      "    Can't uninstall 'websocket-client'. No files were found to uninstall.\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Not uninstalling sniffio at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b6770f8f-39f9-4a94-982d-ac5eecc2fd66\n",
      "    Can't uninstall 'sniffio'. No files were found to uninstall.\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.1.0\n",
      "    Not uninstalling attrs at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b6770f8f-39f9-4a94-982d-ac5eecc2fd66\n",
      "    Can't uninstall 'attrs'. No files were found to uninstall.\n",
      "Successfully installed PySocks-1.7.1 attrs-24.2.0 fake_useragent-1.5.1 outcome-1.3.0.post0 selenium-4.24.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.26.2 trio-websocket-0.11.1 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "pip install fake_useragent selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e8db63-da5f-4d90-bcdd-d88db87690cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Depth Chart scraping and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7054197d-0ca2-49e1-b2ca-3f76850685fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Army Black Knights\n",
      "Charlotte 49ers\n",
      "East Carolina Pirates\n",
      "Florida Atlantic Owls\n",
      "Memphis Tigers\n",
      "Navy Midshipmen\n",
      "North Texas Mean Green\n",
      "Rice Owls\n",
      "South Florida Bulls\n",
      "Temple Owls\n",
      "Tulane Green Wave\n",
      "Tulsa Golden Hurricane\n",
      "UAB Blazers\n",
      "UTSA Roadrunners\n",
      "Boston College Eagles\n",
      "California Golden Bears\n",
      "Clemson Tigers\n",
      "Duke Blue Devils\n",
      "Florida State Seminoles\n",
      "Georgia Tech Yellow Jackets\n",
      "Louisville Cardinals\n",
      "Miami Hurricanes\n",
      "North Carolina Tar Heels\n",
      "North Carolina State Wolfpack\n",
      "Pittsburgh Panthers\n",
      "SMU Mustangs\n",
      "Stanford Cardinal\n",
      "Syracuse Orange\n",
      "Virginia Cavaliers\n",
      "Virginia Tech Hokies\n",
      "Wake Forest Demon Deacons\n",
      "Illinois Fighting Illini\n",
      "Indiana Hoosiers\n",
      "Iowa Hawkeyes\n",
      "Maryland Terrapins\n",
      "Michigan Wolverines\n",
      "Michigan State Spartans\n",
      "Minnesota Golden Gophers\n",
      "Nebraska Cornhuskers\n",
      "Northwestern Wildcats\n",
      "Ohio State Buckeyes\n",
      "Oregon Ducks\n",
      "Penn State Nittany Lions\n",
      "Purdue Boilermakers\n",
      "Rutgers Scarlet Knights\n",
      "UCLA Bruins\n",
      "USC Trojans\n",
      "Washington Huskies\n",
      "Wisconsin Badgers\n",
      "Arizona Wildcats\n",
      "Arizona State Sun Devils\n",
      "Baylor Bears\n",
      "BYU Cougars\n",
      "Central Florida Knights\n",
      "Cincinnati Bearcats\n",
      "Colorado Buffaloes\n",
      "Houston Cougars\n",
      "Iowa State Cyclones\n",
      "Kansas Jayhawks\n",
      "Kansas State Wildcats\n",
      "Oklahoma State Cowboys\n",
      "TCU Horned Frogs\n",
      "Texas Tech Red Raiders\n",
      "Utah Utes\n",
      "West Virginia Mountaineers\n",
      "Florida International Panthers\n",
      "Jacksonville State Gamecocks\n",
      "Kennesaw State Owls\n",
      "Liberty Flames\n",
      "Louisiana Tech Bulldogs\n",
      "Middle Tennessee Blue Raiders\n",
      "New Mexico State Aggies\n",
      "Sam Houston Bearkats\n",
      "UTEP Miners\n",
      "Western Kentucky Hilltoppers\n",
      "Connecticut Huskies\n",
      "Massachusetts Minutemen\n",
      "Notre Dame Fighting Irish\n",
      "Akron Zips\n",
      "Ball State Cardinals\n",
      "Bowling Green Falcons\n",
      "Buffalo Bulls\n",
      "Central Michigan Chippewas\n",
      "Eastern Michigan Eagles\n",
      "Kent State Golden Flashes\n",
      "Miami (Ohio) RedHawks\n",
      "Northern Illinois Huskies\n",
      "Ohio Bobcats\n",
      "Toledo Rockets\n",
      "Western Michigan Broncos\n",
      "Air Force Falcons\n",
      "Boise State Broncos\n",
      "Colorado State Rams\n",
      "Fresno State Bulldogs\n",
      "Hawaii Rainbow Warriors\n",
      "Nevada Wolf Pack\n",
      "New Mexico Lobos\n",
      "San Diego State Aztecs\n",
      "San Jose State Spartans\n",
      "UNLV Rebels\n",
      "Utah State Aggies\n",
      "Wyoming Cowboys\n",
      "Oregon State Beavers\n",
      "Washington State Cougars\n",
      "Alabama Crimson Tide\n",
      "Arkansas Razorbacks\n",
      "Auburn Tigers\n",
      "Florida Gators\n",
      "Georgia Bulldogs\n",
      "Kentucky Wildcats\n",
      "LSU Tigers\n",
      "Mississippi Rebels\n",
      "Mississippi State Bulldogs\n",
      "Missouri Tigers\n",
      "Oklahoma Sooners\n",
      "South Carolina Gamecocks\n",
      "Tennessee Volunteers\n",
      "Texas Longhorns\n",
      "Texas A&M Aggies\n",
      "Vanderbilt Commodores\n",
      "Appalachian State Mountaineers\n",
      "Arkansas State Red Wolves\n",
      "Coastal Carolina Chanticleers\n",
      "Georgia Southern Eagles\n",
      "Georgia State Panthers\n",
      "James Madison Dukes\n",
      "Louisiana Ragin' Cajuns\n",
      "Louisiana-Monroe Warhawks\n",
      "Marshall Thundering Herd\n",
      "Old Dominion Monarchs\n",
      "South Alabama Jaguars\n",
      "Southern Miss Golden Eagles\n",
      "Texas State Bobcats\n",
      "Troy Trojans\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.ourlads.com/ncaa-football-depth-charts'\n",
    "\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "headers = {'User-Agent': userAgent}\n",
    "page = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "team_links = []\n",
    "team_link = soup.find_all('div', class_= \"nfl-dc-mm-team-links\")\n",
    "for i in team_link:\n",
    "    team_links.append('https://www.ourlads.com/ncaa-football-depth-charts/'+ i.a['href'])\n",
    "\n",
    "team_links_depth_chart = team_links[1:]\n",
    "team_links_roster = [url.replace('depth-chart.aspx', 'roster.aspx') for url in team_links]\n",
    "team_links_roster = team_links_roster[1:]\n",
    "master_df = []\n",
    "\n",
    "def get_all_depth_chart(url):\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    head = {'User-Agent': userAgent}\n",
    "    page = requests.get(url, headers = head)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    team_name = soup.find('div', {'class': 'pt-team'}).text.strip()\n",
    "\n",
    "    table = soup.find('table', class_='table table-bordered')\n",
    "    # Extract the headers\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        # Each cell within the row\n",
    "        cells = [td.text.strip() for td in tr.find_all('td')]\n",
    "        rows.append(cells)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df['team_name'] = team_name\n",
    "    print(team_name)\n",
    "    df['field_pos'] = df['Pos'].where(df['Pos'].isin(['Offense', 'Defense', 'Special Teams']))\n",
    "\n",
    "    # Forward fill the 'field_pos' column to propagate values downwards\n",
    "    df['field_pos'] = df['field_pos'].ffill()\n",
    "    df = df[~df['Pos'].isin(['Offense', 'Defense', 'Special Teams', 'OFF','ST','DEF'])]\n",
    "    df.rename(columns={'Player 1': '1st String','Player 2': '2nd String','Player 3': '3rd String','Player 4': '4th String','Player 5': '5th String','Pos':'Position','No.':'No1'}, inplace=True)\n",
    "    no_counter = 2  # Start with 'No2'\n",
    "\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        if col == 'No':\n",
    "            new_columns.append(f'No{no_counter}')\n",
    "            no_counter += 1\n",
    "        else:\n",
    "            new_columns.append(col)\n",
    "\n",
    "    df.columns = new_columns\n",
    "\n",
    "    df['1st String'] = df['No1'].astype(str) + ' ' + df['1st String']\n",
    "    df['2nd String'] = df['No2'].astype(str) + ' ' + df['2nd String']\n",
    "    df['3rd String'] = df['No3'].astype(str) + ' ' + df['3rd String']\n",
    "    df['4th String'] = df['No4'].astype(str) + ' ' + df['4th String']\n",
    "    df['5th String'] = df['No5'].astype(str) + ' ' + df['5th String']\n",
    "\n",
    "    df = df.drop(columns=['No1', 'No2', 'No3','No4','No5'])\n",
    "\n",
    "\n",
    "    df = df.melt(id_vars=['Position','field_pos','team_name'], \n",
    "                        value_vars=['1st String', '2nd String', '3rd String','4th String', '5th String'], \n",
    "                        var_name='String Order', \n",
    "                        value_name='Player Name')\n",
    "    # Step 1: Extract the Player Number\n",
    "    df['Player Number'] = df['Player Name'].str.extract(r'^(\\d+)')\n",
    "\n",
    "    # Step 2: Remove the Player Number from the Player Name\n",
    "    df['Player'] = df['Player Name'].str.replace(r'^\\d+\\s+', '', regex=True)\n",
    "\n",
    "    # Step 3: Split the Player Name into First Name and Other Names\n",
    "    df[['First Name', 'Other Names']] = df['Player'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "    # Step 4: Drop the original 'Player' column as it's now split\n",
    "    df = df.drop(columns=['Player Name','Player'])\n",
    "\n",
    "    df['First Name']=df['First Name'].str.replace(',','')\n",
    "    df[['Last Name', 'School year']] = df['Other Names'].str.split(' ', n=1, expand=True)\n",
    "    df = df.drop(columns=['Other Names'])\n",
    "    master_df.append(df)\n",
    "    \n",
    "\n",
    "for i in team_links_depth_chart:\n",
    "    get_all_depth_chart(i)\n",
    "\n",
    "df_depth_chart = pd.concat(master_df)\n",
    "df_depth_chart = df_depth_chart.dropna(subset=['Player Number'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f7b60b0-a6cd-4d69-aaf7-1e273bbe3b68",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Quality for Depth Chart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbb04b6c-5d31-4d0d-9f9d-337e655349d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs('/dbfs/FileStore', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37d39851-1645-4b66-ae90-837c34f32273",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows in the column are 'pass'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def run_data_quality_checks(df):\n",
    "    # Initialize a list to store all check results\n",
    "    check_results = []\n",
    "\n",
    "    # Check for null values in 'Position', 'field_pos', and 'team_name'\n",
    "    for column in ['Position', 'field_pos', 'team_name']:\n",
    "        null_count = df[column].isnull().sum()\n",
    "        check_results.append({\n",
    "            'check': f\"'{column}' not null\",\n",
    "            'result': 'Pass' if null_count == 0 else 'Fail',\n",
    "            'details': f\"{null_count} null values found\"\n",
    "        })\n",
    "\n",
    "    # Check if 'Player Number' is an integer\n",
    "    player_number_check = df['Player Number'].astype(str).str.match(r'^\\d+$').all()\n",
    "    check_results.append({\n",
    "        'check': \"'Player Number' is integer\",\n",
    "        'result': 'Pass' if player_number_check else 'Fail',\n",
    "        'details': \"All values are integers\" if player_number_check else \"Non-integer values found\"\n",
    "    })\n",
    "\n",
    "    # Check if 'String Order' belongs to predefined values\n",
    "    valid_string_orders = ['1st String', '2nd String', '3rd String', '4th String', '5th String']\n",
    "    string_order_check = df['String Order'].isin(valid_string_orders).all()\n",
    "    check_results.append({\n",
    "        'check': \"'String Order' in predefined set\",\n",
    "        'result': 'Pass' if string_order_check else 'Fail',\n",
    "        'details': \"All values are valid\" if string_order_check else \"Invalid values found\"\n",
    "    })\n",
    "\n",
    "    # Check if 'field_pos' belongs to predefined values\n",
    "    valid_field_pos = ['Defense', 'Offense', 'Special Teams']\n",
    "    field_pos_check = df['field_pos'].isin(valid_field_pos).all()\n",
    "    check_results.append({\n",
    "        'check': \"'field_pos' in predefined set\",\n",
    "        'result': 'Pass' if field_pos_check else 'Fail',\n",
    "        'details': \"All values are valid\" if field_pos_check else \"Invalid values found\"\n",
    "    })\n",
    "\n",
    "    # Convert check results to a DataFrame for easy viewing\n",
    "    results_df = pd.DataFrame(check_results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "results = run_data_quality_checks(df_depth_chart)\n",
    "\n",
    "if (results['result'] == 'Pass').all():\n",
    "    df_depth_chart.to_parquet('/dbfs/FileStore/depth_chart.parquet')\n",
    "    print(\"All rows in the column are 'pass'.\")\n",
    "else:\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5b6ba1f-ece2-4c45-8853-28f369577147",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Roster scraping and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cc10ad5-1c86-4e0a-b560-610575d78613",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Army Black Knights\n",
      "Charlotte 49ers\n",
      "East Carolina Pirates\n",
      "Florida Atlantic Owls\n",
      "Memphis Tigers\n",
      "Navy Midshipmen\n",
      "North Texas Mean Green\n",
      "Rice Owls\n",
      "South Florida Bulls\n",
      "Temple Owls\n",
      "Tulane Green Wave\n",
      "Tulsa Golden Hurricane\n",
      "UAB Blazers\n",
      "UTSA Roadrunners\n",
      "Boston College Eagles\n",
      "California Golden Bears\n",
      "Clemson Tigers\n",
      "Duke Blue Devils\n",
      "Florida State Seminoles\n",
      "Georgia Tech Yellow Jackets\n",
      "Louisville Cardinals\n",
      "Miami Hurricanes\n",
      "North Carolina Tar Heels\n",
      "North Carolina State Wolfpack\n",
      "Pittsburgh Panthers\n",
      "SMU Mustangs\n",
      "Stanford Cardinal\n",
      "Syracuse Orange\n",
      "Virginia Cavaliers\n",
      "Virginia Tech Hokies\n",
      "Wake Forest Demon Deacons\n",
      "Illinois Fighting Illini\n",
      "Indiana Hoosiers\n",
      "Iowa Hawkeyes\n",
      "Maryland Terrapins\n",
      "Michigan Wolverines\n",
      "Michigan State Spartans\n",
      "Minnesota Golden Gophers\n",
      "Nebraska Cornhuskers\n",
      "Northwestern Wildcats\n",
      "Ohio State Buckeyes\n",
      "Oregon Ducks\n",
      "Penn State Nittany Lions\n",
      "Purdue Boilermakers\n",
      "Rutgers Scarlet Knights\n",
      "UCLA Bruins\n",
      "USC Trojans\n",
      "Washington Huskies\n",
      "Wisconsin Badgers\n",
      "Arizona Wildcats\n",
      "Arizona State Sun Devils\n",
      "Baylor Bears\n",
      "BYU Cougars\n",
      "Central Florida Knights\n",
      "Cincinnati Bearcats\n",
      "Colorado Buffaloes\n",
      "Houston Cougars\n",
      "Iowa State Cyclones\n",
      "Kansas Jayhawks\n",
      "Kansas State Wildcats\n",
      "Oklahoma State Cowboys\n",
      "TCU Horned Frogs\n",
      "Texas Tech Red Raiders\n",
      "Utah Utes\n",
      "West Virginia Mountaineers\n",
      "Florida International Panthers\n",
      "Jacksonville State Gamecocks\n",
      "Kennesaw State Owls\n",
      "Liberty Flames\n",
      "Louisiana Tech Bulldogs\n",
      "Middle Tennessee Blue Raiders\n",
      "New Mexico State Aggies\n",
      "Sam Houston Bearkats\n",
      "UTEP Miners\n",
      "Western Kentucky Hilltoppers\n",
      "Connecticut Huskies\n",
      "Massachusetts Minutemen\n",
      "Notre Dame Fighting Irish\n",
      "Akron Zips\n",
      "Ball State Cardinals\n",
      "Bowling Green Falcons\n",
      "Buffalo Bulls\n",
      "Central Michigan Chippewas\n",
      "Eastern Michigan Eagles\n",
      "Kent State Golden Flashes\n",
      "Miami (Ohio) RedHawks\n",
      "Northern Illinois Huskies\n",
      "Ohio Bobcats\n",
      "Toledo Rockets\n",
      "Western Michigan Broncos\n",
      "Air Force Falcons\n",
      "Boise State Broncos\n",
      "Colorado State Rams\n",
      "Fresno State Bulldogs\n",
      "Hawaii Rainbow Warriors\n",
      "Nevada Wolf Pack\n",
      "New Mexico Lobos\n",
      "San Diego State Aztecs\n",
      "San Jose State Spartans\n",
      "UNLV Rebels\n",
      "Utah State Aggies\n",
      "Wyoming Cowboys\n",
      "Oregon State Beavers\n",
      "Washington State Cougars\n",
      "Alabama Crimson Tide\n",
      "Arkansas Razorbacks\n",
      "Auburn Tigers\n",
      "Florida Gators\n",
      "Georgia Bulldogs\n",
      "Kentucky Wildcats\n",
      "LSU Tigers\n",
      "Mississippi Rebels\n",
      "Mississippi State Bulldogs\n",
      "Missouri Tigers\n",
      "Oklahoma Sooners\n",
      "South Carolina Gamecocks\n",
      "Tennessee Volunteers\n",
      "Texas Longhorns\n",
      "Texas A&M Aggies\n",
      "Vanderbilt Commodores\n",
      "Appalachian State Mountaineers\n",
      "Arkansas State Red Wolves\n",
      "Coastal Carolina Chanticleers\n",
      "Georgia Southern Eagles\n",
      "Georgia State Panthers\n",
      "James Madison Dukes\n",
      "Louisiana Ragin' Cajuns\n",
      "Louisiana-Monroe Warhawks\n",
      "Marshall Thundering Herd\n",
      "Old Dominion Monarchs\n",
      "South Alabama Jaguars\n",
      "Southern Miss Golden Eagles\n",
      "Texas State Bobcats\n",
      "Troy Trojans\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Class</th>\n",
       "      <th>High School</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Other Names</th>\n",
       "      <th>team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>DL</td>\n",
       "      <td>6'1</td>\n",
       "      <td>275</td>\n",
       "      <td>SO</td>\n",
       "      <td>Holy Cross</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Ali</td>\n",
       "      <td>Amir</td>\n",
       "      <td>Army Black Knights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>PT</td>\n",
       "      <td>6'1</td>\n",
       "      <td>213</td>\n",
       "      <td>JR</td>\n",
       "      <td>Independence</td>\n",
       "      <td>Franklin, TN</td>\n",
       "      <td>Allan</td>\n",
       "      <td>Cooper</td>\n",
       "      <td>Army Black Knights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>WR</td>\n",
       "      <td>6'1</td>\n",
       "      <td>205</td>\n",
       "      <td>FR</td>\n",
       "      <td>Edina</td>\n",
       "      <td>Edina, MN</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>Brady</td>\n",
       "      <td>Army Black Knights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>OL</td>\n",
       "      <td>6'2</td>\n",
       "      <td>285</td>\n",
       "      <td>SO</td>\n",
       "      <td>Billy Ryan</td>\n",
       "      <td>Denton, TX</td>\n",
       "      <td>Appleton</td>\n",
       "      <td>Henry</td>\n",
       "      <td>Army Black Knights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78</td>\n",
       "      <td>OL</td>\n",
       "      <td>6'5</td>\n",
       "      <td>317</td>\n",
       "      <td>FR</td>\n",
       "      <td>Lower Merion</td>\n",
       "      <td>Ardmore, PA</td>\n",
       "      <td>Archawski</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>Army Black Knights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5</td>\n",
       "      <td>DE/OLB</td>\n",
       "      <td>6'4</td>\n",
       "      <td>230</td>\n",
       "      <td>RS JR/TR</td>\n",
       "      <td>Cardinal Gibbons</td>\n",
       "      <td>Carver Ranches, FL</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Jah-Mal</td>\n",
       "      <td>Troy Trojans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4</td>\n",
       "      <td>RB</td>\n",
       "      <td>5'1</td>\n",
       "      <td>199</td>\n",
       "      <td>RS JR</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Mobile, AL</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Jarris</td>\n",
       "      <td>Troy Trojans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>86</td>\n",
       "      <td>TE</td>\n",
       "      <td>6'4</td>\n",
       "      <td>241</td>\n",
       "      <td>RS FR</td>\n",
       "      <td>The King's Academy</td>\n",
       "      <td>West Palm Beach, FL</td>\n",
       "      <td>Worley</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>Troy Trojans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>9</td>\n",
       "      <td>CB</td>\n",
       "      <td>6'1</td>\n",
       "      <td>187</td>\n",
       "      <td>SR/TR</td>\n",
       "      <td>Orange Lutheran</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>Yancey</td>\n",
       "      <td>Damaje</td>\n",
       "      <td>Troy Trojans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>35</td>\n",
       "      <td>PK</td>\n",
       "      <td>6'</td>\n",
       "      <td>214</td>\n",
       "      <td>FR</td>\n",
       "      <td>Madison Ridgeland Academy</td>\n",
       "      <td>Madison, MS</td>\n",
       "      <td>Zuluaga</td>\n",
       "      <td>Max</td>\n",
       "      <td>Troy Trojans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16132 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player Number Position height  ...  First Name Other Names           team_name\n",
       "1               90       DL    6'1  ...         Ali        Amir  Army Black Knights\n",
       "2               38       PT    6'1  ...       Allan      Cooper  Army Black Knights\n",
       "3               47       WR    6'1  ...    Anderson       Brady  Army Black Knights\n",
       "4               58       OL    6'2  ...    Appleton       Henry  Army Black Knights\n",
       "5               78       OL    6'5  ...   Archawski      Xavier  Army Black Knights\n",
       "..             ...      ...    ...  ...         ...         ...                 ...\n",
       "122              5   DE/OLB    6'4  ...    Williams     Jah-Mal        Troy Trojans\n",
       "123              4       RB    5'1  ...    Williams      Jarris        Troy Trojans\n",
       "124             86       TE    6'4  ...      Worley     Jackson        Troy Trojans\n",
       "125              9       CB    6'1  ...      Yancey      Damaje        Troy Trojans\n",
       "126             35       PK     6'  ...     Zuluaga         Max        Troy Trojans\n",
       "\n",
       "[16132 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_df = []\n",
    "def get_roster(url):\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    head = {'User-Agent': userAgent}\n",
    "    page = requests.get(url, headers = head)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    team_name = soup.find('div', {'class': 'pt-team'}).text.strip()\n",
    "\n",
    "    table = soup.find('table', class_='table table-bordered')\n",
    "    # Extract the headers\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "    rows = []\n",
    "    for tr in table.find('tbody').find_all('tr'):\n",
    "        # Each cell within the row\n",
    "        cells = [td.text.strip() for td in tr.find_all('td')]\n",
    "        rows.append(cells)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df = df[~df['Player'].isin(['Active Players'])]\n",
    "    df.rename(columns={'#': 'Player Number','Pos.': 'Position','HT':'height','WT':'Weight'}, inplace=True)\n",
    "    df[['First Name', 'Other Names']] = df['Player'].str.split(' ', n=1, expand=True)\n",
    "    df['First Name']=df['First Name'].str.replace(',','')\n",
    "    df['height'] = pd.to_numeric(df['height'])\n",
    "    df['height']= (df['height'] /10).astype(int)\n",
    "    df['height'] = df['height'].astype(str)\n",
    "\n",
    "    df['height'] = df['height'].str.rstrip('0')\n",
    "    single_digit_mask = df['height'].str.len() == 1\n",
    "    df['formatted_height'] = np.where(single_digit_mask,\n",
    "                                    df['height'] + \"'\",\n",
    "                                    df['height'].str[0] + \"'\" + df['height'].str[1:])\n",
    "    df['formatted_height']=df['formatted_height'].str.replace('0','')\n",
    "    df['height'] = df['formatted_height']\n",
    "    df = df.drop(columns=['Player','formatted_height'])\n",
    "    df['team_name'] = team_name\n",
    "    print(team_name)\n",
    "    all_df.append(df)\n",
    "\n",
    "for i in team_links_roster:\n",
    "    get_roster(i)\n",
    "\n",
    "df_roster = pd.concat(all_df)\n",
    "\n",
    "\n",
    "df_roster['Weight'] = pd.to_numeric(df_roster['Weight'], errors='coerce')\n",
    "df_roster['Player Number'] = pd.to_numeric(df_roster['Player Number'], errors='coerce')\n",
    "df_roster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06f962c2-a3b9-46b3-844c-dc7df444fb2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Quality for Roster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7865036b-aa18-4ac2-b6c8-d80f52193e06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows in the column are 'pass'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def run_roster_data_quality_checks(df):\n",
    "    check_results = []\n",
    "\n",
    "    # Check 'Player Number' is not null and is an integer\n",
    "    player_number_null = df['Player Number'].isnull().sum()\n",
    "    player_number_int = df['Player Number'].dtype == 'int64'\n",
    "    check_results.extend([\n",
    "        {\n",
    "            'check': \"'Player Number' not null\",\n",
    "            'result': 'Pass' if player_number_null == 0 else 'Fail',\n",
    "            'details': f\"{player_number_null} null values found\"\n",
    "        },\n",
    "        {\n",
    "            'check': \"'Player Number' is integer\",\n",
    "            'result': 'Pass' if player_number_int else 'Fail',\n",
    "            'details': f\"Type is {df['Player Number'].dtype}\"\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # Check 'Position' is not null\n",
    "    position_null = df['Position'].isnull().sum()\n",
    "    check_results.append({\n",
    "        'check': \"'Position' not null\",\n",
    "        'result': 'Pass' if position_null == 0 else 'Fail',\n",
    "        'details': f\"{position_null} null values found\"\n",
    "    })\n",
    "\n",
    "    # Check 'Weight' is integer and within range\n",
    "    weight_int = df['Weight'].dtype == 'int64'\n",
    "    weight_range = df['Weight'].between(100, 450).all()\n",
    "    check_results.extend([\n",
    "        {\n",
    "            'check': \"'Weight' is integer\",\n",
    "            'result': 'Pass' if weight_int else 'Fail',\n",
    "            'details': f\"Type is {df['Weight'].dtype}\"\n",
    "        },\n",
    "        {\n",
    "            'check': \"'Weight' between 100 and 450\",\n",
    "            'result': 'Pass' if weight_range else 'Fail',\n",
    "            'details': f\"Range is {df['Weight'].min()} to {df['Weight'].max()}\"\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # Check 'team_name' is not null\n",
    "    team_name_null = df['team_name'].isnull().sum()\n",
    "    check_results.append({\n",
    "        'check': \"'team_name' not null\",\n",
    "        'result': 'Pass' if team_name_null == 0 else 'Fail',\n",
    "        'details': f\"{team_name_null} null values found\"\n",
    "    })\n",
    "\n",
    "    # Convert check results to a DataFrame\n",
    "    results_df = pd.DataFrame(check_results)\n",
    "    return results_df\n",
    "\n",
    "results = run_roster_data_quality_checks(df_roster)\n",
    "\n",
    "if (results['result'] == 'Pass').all():\n",
    "    df_roster.to_parquet('/dbfs/FileStore/roster.parquet')\n",
    "    print(\"All rows in the column are 'pass'.\")\n",
    "else:\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1109125c-3518-41c9-bf9b-a57d43fea0aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Player stats scraping of ESPN with Selenium\n",
    "## Data quality checks attached as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13dbac5c-318e-4c50-ba6a-405a595a42fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.espn.com/college-football/stats/player/_/view/scoring\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".AnchorLink.loadMore__link\"}\n",
      "  (Session info: chrome=130.0.6723.0); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "#0 0x55ab57b71332 <unknown>\n",
      "#1 0x55ab57b6315e <unknown>\n",
      "#2 0x55ab57612e97 <unknown>\n",
      "#3 0x55ab5765ab13 <unknown>\n",
      "#4 0x55ab5765adf1 <unknown>\n",
      "#5 0x55ab5769f2f4 <unknown>\n",
      "#6 0x55ab5767f1bd <unknown>\n",
      "#7 0x55ab5764ffcf <unknown>\n",
      "#8 0x55ab5769cfb7 <unknown>\n",
      "#9 0x55ab5767ee33 <unknown>\n",
      "#10 0x55ab5764f051 <unknown>\n",
      "#11 0x55ab5764e149 <unknown>\n",
      "#12 0x55ab5764ee2c <unknown>\n",
      "#13 0x55ab57b1e9cf <unknown>\n",
      "#14 0x55ab57b39959 <unknown>\n",
      "#15 0x55ab57b393cb <unknown>\n",
      "#16 0x55ab57b39db5 <unknown>\n",
      "#17 0x55ab57b290a3 <unknown>\n",
      "#18 0x55ab57b3a150 <unknown>\n",
      "#19 0x55ab57b0f1c1 <unknown>\n",
      "#20 0x55ab57b53838 <unknown>\n",
      "#21 0x55ab57b539c9 <unknown>\n",
      "#22 0x55ab57b62495 <unknown>\n",
      "#23 0x7fe9ef69fac3 <unknown>\n",
      "#24 0x7fe9ef731850 <unknown>\n",
      "\n",
      "all show more clicked\n",
      "All rows in the column are 'pass'.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# URLs to scrape data from ESPN's college football player stats pages\n",
    "urls = ['https://www.espn.com/college-football/stats/player',\n",
    "        'https://www.espn.com/college-football/stats/player/_/stat/rushing',\n",
    "        'https://www.espn.com/college-football/stats/player/_/stat/receiving',\n",
    "        'https://www.espn.com/college-football/stats/player/_/view/scoring']\n",
    "\n",
    "def get_espn_college_football_stats(url):\n",
    "    s = Service('/tmp/chrome/latest/chromedriver_linux64/chromedriver')\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = \"/tmp/chrome/latest/chrome-linux/chrome\"\n",
    "\n",
    "    ua = UserAgent()  # Instantiate UserAgent to generate random user agents\n",
    "    userAgent = ua.random  # Generate a random user-agent string\n",
    "    options.add_argument(f'user-agent={userAgent}')  # Set the random user-agent string in browser options\n",
    "    options.add_argument('--blink-settings=imagesEnabled=false')  \n",
    "    options.add_argument('headless')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--remote-debugging-port=9222')\n",
    "    options.add_argument('--homedir=/tmp/chrome/chrome-user-data-dir')\n",
    "    options.add_argument('--user-data-dir=/tmp/chrome/chrome-user-data-dir')\n",
    "    prefs = {\"download.default_directory\":\"/tmp/chrome/chrome-user-data-di\",\n",
    "            \"download.prompt_for_download\":False\n",
    "    }\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "    driver = webdriver.Chrome(service=s, options=options)\n",
    "\n",
    "    driver.get(url)  # Load the specified URL in the Chrome browser\n",
    "        \n",
    "    time.sleep(5)  # Pause for 5 seconds to allow the page to load completely\n",
    "\n",
    "    # Continuously click the \"Show More\" button until no more data can be loaded\n",
    "    while True:\n",
    "        try:\n",
    "            # Locate the \"Show More\" button by its class name\n",
    "            element = driver.find_element(By.CLASS_NAME, 'AnchorLink.loadMore__link')\n",
    "            # Wait until the \"Show More\" button is clickable\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CLASS_NAME, 'AnchorLink.loadMore__link')))\n",
    "            # Scroll the \"Show More\" button into view\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "            # Click the \"Show More\" button to load more data\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            time.sleep(5)  # Pause for 5 seconds between clicks\n",
    "        except Exception as e:  # Catch any exception if \"Show More\" button is not found\n",
    "            print(e)  # Print the exception message\n",
    "            break  # Exit the loop if no more data can be loaded\n",
    "        print(\"Complete\")  # Log progress when a \"Show More\" click is successful\n",
    "\n",
    "    print('all show more clicked')  # Indicate that all data has been loaded\n",
    "\n",
    "    page = driver.page_source  # Get the page source (HTML content)\n",
    "\n",
    "    # Clean the HTML by removing unwanted rows (optional step)\n",
    "    cleaned_html = re.sub(r'<tr class=\"Table__TR.Table__even\">.*?</tr>', '', str(page), flags=re.DOTALL)\n",
    "\n",
    "    # Parse the cleaned HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(cleaned_html, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all('table')  # Find all table elements in the HTML\n",
    "    driver.quit()  # Close the Chrome browser\n",
    "\n",
    "    dataframes = []  # List to store extracted data as DataFrames\n",
    "\n",
    "    # Loop over each table found in the HTML and extract it into a pandas DataFrame\n",
    "    for table in tables:\n",
    "        headers = [th.text.strip() for th in table.find_all('th', class_='Table__TH')]  # Extract table headers\n",
    "        headers = list(filter(None, headers))  # Filter out empty headers\n",
    "        \n",
    "        rows = []  # List to store rows of table data\n",
    "        # Extract data from each row in the table\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = [cell.text.strip() for cell in row.find_all('td')]  # Extract text from each table cell\n",
    "            if cells:  # Avoid adding empty rows\n",
    "                rows.append(cells)\n",
    "        \n",
    "        # Create a DataFrame if headers exist; otherwise, use default row indexing\n",
    "        if headers:\n",
    "            df = pd.DataFrame(rows, columns=headers)  # Create DataFrame with headers\n",
    "        else:\n",
    "            df = pd.DataFrame(rows)  # Create DataFrame without headers\n",
    "        \n",
    "        dataframes.append(df)  # Append the DataFrame to the list\n",
    "\n",
    "    # Concatenate all the DataFrames for the current page into a single DataFrame\n",
    "    dataframes = pd.concat(dataframes, axis=1)\n",
    "\n",
    "    # Extract the team abbreviation from the 'Name' column\n",
    "    dataframes['College'] = dataframes['Name'].str.extract(r'([A-Z]{2,})$')\n",
    "\n",
    "    # Remove the uppercase letters (team abbreviations) from the 'Name' column\n",
    "    dataframes['Name'] = dataframes['Name'].str.replace(r'([A-Z]{2,})$', '', regex=True).str.strip()\n",
    "    dataframes.rename(columns={'POS': 'Position','RK': 'Rank'}, inplace=True)\n",
    "    dataframes[\"Rank\"] = pd.to_numeric(dataframes[\"Rank\"])\n",
    "    dataframes.loc[dataframes['Name'].str.contains('TA&M') & dataframes['College'].isnull(), 'College'] = 'TA&M'\n",
    "\n",
    "    # Remove 'TA&M' from the 'name' column\n",
    "    dataframes['Name'] = dataframes['Name'].str.replace('TA&M', '').str.strip()\n",
    "    dataframes = dataframes[dataframes['Position'] != '-']\n",
    "\n",
    "    df = dataframes\n",
    "    check_results = []\n",
    "\n",
    "    # Check 'Rk' (Rank) is not null and is an integer\n",
    "    rk_null = df['Rank'].isnull().sum()\n",
    "    rk_int = df['Rank'].dtype == 'int64'\n",
    "    check_results.extend([\n",
    "        {\n",
    "            'check': \"'Rank' not null\",\n",
    "            'result': 'Pass' if rk_null == 0 else 'Fail',\n",
    "            'details': f\"{rk_null} null values found\"\n",
    "        },\n",
    "        {\n",
    "            'check': \"'Rank' is integer\",\n",
    "            'result': 'Pass' if rk_int else 'Fail',\n",
    "            'details': f\"Type is {df['Rank'].dtype}\"\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # Check 'Name' is not null and is a string\n",
    "    name_null = df['Name'].isnull().sum()\n",
    "    name_string = df['Name'].dtype == 'object'\n",
    "    check_results.extend([\n",
    "        {\n",
    "            'check': \"'Name' not null\",\n",
    "            'result': 'Pass' if name_null == 0 else 'Fail',\n",
    "            'details': f\"{name_null} null values found\"\n",
    "        },\n",
    "        {\n",
    "            'check': \"'Name' is string\",\n",
    "            'result': 'Pass' if name_string else 'Fail',\n",
    "            'details': f\"Type is {df['Name'].dtype}\"\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # Check 'POS' is not null and is in a set of valid positions\n",
    "    valid_positions = {\n",
    "    \"DL\",\n",
    "    \"EDGE\",\n",
    "    \"S\",\n",
    "    \"QB\",\n",
    "    \"RB\",  # Running Back\n",
    "    \"FB\",  # Fullback\n",
    "    \"WR\",  # Wide Receiver\n",
    "    \"TE\",  # Tight End\n",
    "    \"LT\",  # Left Tackle\n",
    "    \"LG\",  # Left Guard\n",
    "    \"C\",   # Center\n",
    "    \"RG\",  # Right Guard\n",
    "    \"RT\",  # Right Tackle\n",
    "    \"DT\",  # Defensive Tackle\n",
    "    \"DE\",  # Defensive End\n",
    "    \"NT\",  # Nose Tackle\n",
    "    \"LB\",  # Linebacker\n",
    "    \"MLB\", # Middle Linebacker\n",
    "    \"OLB\", # Outside Linebacker\n",
    "    \"CB\",  # Cornerback\n",
    "    \"FS\",  # Free Safety\n",
    "    \"SS\",  # Strong Safety\n",
    "    \"DB\",  # Defensive Back (general term for CB and S)\n",
    "    \"OL\",  # Offensive Line (general term for LT, LG, C, RG, RT)\n",
    "    \"PK\",  # Placekicker\n",
    "    \"K\",   # Kicker\n",
    "    \"P\",   # Punter\n",
    "    \"LS\",  # Long Snapper\n",
    "    \"KR\",  # Kick Returner\n",
    "    \"PR\",  # Punt Returner\n",
    "    \"G\",   # Gunner (Special Teams)\n",
    "    \"H\",   # Holder\n",
    "    \"KO\"   # Kickoff Specialist\n",
    "}  # Add more as needed\n",
    "    pos_null = df['Position'].isnull().sum()\n",
    "    pos_valid = df['Position'].isin(valid_positions).all()\n",
    "    check_results.extend([\n",
    "        {\n",
    "            'check': \"'Position' not null\",\n",
    "            'result': 'Pass' if pos_null == 0 else 'Fail',\n",
    "            'details': f\"{pos_null} null values found\"\n",
    "        },\n",
    "        {\n",
    "            'check': \"'Position' is valid\",\n",
    "            'result': 'Pass' if pos_valid else 'Fail',\n",
    "            'details': f\"Invalid positions: {set(df['Position'].unique()) - valid_positions}\"\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # Check 'College' is not null and is a string\n",
    "    College_null = df['College'].isnull().sum()\n",
    "    College_string = df['College'].dtype == 'object'\n",
    "    check_results.extend([\n",
    "        {\n",
    "            'check': \"'College' not null\",\n",
    "            'result': 'Pass' if College_null == 0 else 'Fail',\n",
    "            'details': f\"{College_null} null values found\"\n",
    "        },\n",
    "        {\n",
    "            'check': \"'College' is string\",\n",
    "            'result': 'Pass' if College_string else 'Fail',\n",
    "            'details': f\"Type is {df['College'].dtype}\"\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # Convert check results to a DataFrame\n",
    "    results_df = pd.DataFrame(check_results)\n",
    "    results_df = pd.DataFrame(check_results)\n",
    "    if (results_df['result'] == 'Pass').all():\n",
    "        df.to_parquet(f\"/dbfs/FileStore/player_stats_{url.rstrip('/').split('/')[-1]}.parquet\")\n",
    "        print(\"All rows in the column are 'pass'.\")\n",
    "    else:\n",
    "        print(results_df)\n",
    "\n",
    "for i in urls:\n",
    "    print(i)\n",
    "    get_espn_college_football_stats(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4309fef-a520-4ff2-820e-b3dab32c4ad3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Move all extracted parquet files to your blob storage container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44177d8e-806e-478b-b798-43f9a6206277",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Parquet files removed from dbfs:/FileStore\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set up the blob storage account details\n",
    "account_name = \"testtech\"\n",
    "container_name = \"testtech\"\n",
    "mount_point = \"/mnt/testtech\"\n",
    "storage_key = \"\"\n",
    "\n",
    "# The path to your Parquet files on DBFS\n",
    "dbfs_parquet_path = 'dbfs:/FileStore'\n",
    "\n",
    "# 1. Mount the blob storage container\n",
    "def mount_blob_storage():\n",
    "    if not any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "        dbutils.fs.mount(\n",
    "            source = f\"wasbs://{container_name}@{account_name}.blob.core.windows.net/\",\n",
    "            mount_point = mount_point,\n",
    "            extra_configs = {f\"fs.azure.account.key.{account_name}.blob.core.windows.net\": storage_key}\n",
    "        )\n",
    "    print(\"Blob storage mounted.\")\n",
    "\n",
    "# 2. Create a new folder named with the current date\n",
    "def create_new_folder():\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    new_folder_path = os.path.join(mount_point, current_date)\n",
    "    dbutils.fs.mkdirs(new_folder_path)\n",
    "    print(f\"New folder created: {new_folder_path}\")\n",
    "    return new_folder_path\n",
    "\n",
    "# 3. Move Parquet files to the newly created folder\n",
    "def move_parquet_files_to_blob(new_folder_path):\n",
    "    files = dbutils.fs.ls(dbfs_parquet_path)\n",
    "    \n",
    "    for file in files:\n",
    "        if file.path.endswith(\".parquet\"):\n",
    "            dbutils.fs.mv(file.path, new_folder_path)\n",
    "            print(f\"Moved file {file.path} to {new_folder_path}\")\n",
    "    print(\"All Parquet files moved.\")\n",
    "\n",
    "# 4. Unmount the blob storage container\n",
    "def unmount_blob_storage():\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "    print(\"Blob storage unmounted.\")\n",
    "\n",
    "# 5. Remove the Parquet files from DBFS\n",
    "def remove_parquet_files_from_dbfs():\n",
    "    # List all files in the directory\n",
    "    files = dbutils.fs.ls(dbfs_parquet_path)\n",
    "    \n",
    "    # Loop through the files and remove only the ones with '.parquet' extension\n",
    "    for file in files:\n",
    "        if file.name.endswith(\".parquet\"):\n",
    "            dbutils.fs.rm(file.path)\n",
    "            print(f\"Removed Parquet file: {file.path}\")\n",
    "\n",
    "    print(f\"All Parquet files removed from {dbfs_parquet_path}\")\n",
    "\n",
    "# Main function to run the whole process\n",
    "def move_parquet_files():\n",
    "    mount_blob_storage()  # Mount the blob storage\n",
    "    new_folder_path = create_new_folder()  # Create a date-named folder\n",
    "    move_parquet_files_to_blob(new_folder_path)  # Move files to the new folder\n",
    "    unmount_blob_storage()  # Unmount the blob storage\n",
    "    remove_parquet_files_from_dbfs()  # Delete parquet files from DBFS\n",
    "\n",
    "# Run the process\n",
    "move_parquet_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4ebb9d-c723-4ede-b98d-2e7f8dfdf7f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/FileStore/depth_chart.parquet', name='depth_chart.parquet', size=130382, modificationTime=1726530423000),\n",
       " FileInfo(path='dbfs:/FileStore/player_stats_player.parquet', name='player_stats_player.parquet', size=24218, modificationTime=1726530597000),\n",
       " FileInfo(path='dbfs:/FileStore/player_stats_receiving.parquet', name='player_stats_receiving.parquet', size=47534, modificationTime=1726530915000),\n",
       " FileInfo(path='dbfs:/FileStore/player_stats_rushing.parquet', name='player_stats_rushing.parquet', size=38008, modificationTime=1726530729000),\n",
       " FileInfo(path='dbfs:/FileStore/player_stats_scoring.parquet', name='player_stats_scoring.parquet', size=34965, modificationTime=1726532043000),\n",
       " FileInfo(path='dbfs:/FileStore/roster.parquet', name='roster.parquet', size=375152, modificationTime=1726530556000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/', name='tables/', size=0, modificationTime=1726531786000)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = dbutils.fs.ls('dbfs:/FileStore')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://site.api.espn.com/apis/site/v2/sports/football/college-football/scoreboard\"\n",
    "response = requests.get(url, timeout=10)\n",
    "response.raise_for_status()  # Raise an exception for bad status codes\n",
    "data = response.json()\n",
    "\n",
    "matches = []\n",
    "for event in data.get('events', []):\n",
    "    match = {\n",
    "        'id': event['id'],\n",
    "        'name': event['name'],\n",
    "        'shortName': event['shortName'],\n",
    "        'status': event['status']['type']['name'],\n",
    "        'date': datetime.strptime(event['date'], \"%Y-%m-%dT%H:%MZ\"),\n",
    "        'homeTeam': event['competitions'][0]['competitors'][0]['team']['displayName'],\n",
    "        'homeScore': int(event['competitions'][0]['competitors'][0]['score']),\n",
    "        'awayTeam': event['competitions'][0]['competitors'][1]['team']['displayName'],\n",
    "        'awayScore': int(event['competitions'][0]['competitors'][1]['score'])\n",
    "    }\n",
    "    matches.append(match)\n",
    "df = pd.DataFrame(matches)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>shortName</th>\n",
       "      <th>status</th>\n",
       "      <th>date</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>homeScore</th>\n",
       "      <th>awayTeam</th>\n",
       "      <th>awayScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401628485</td>\n",
       "      <td>Illinois Fighting Illini at Nebraska Cornhuskers</td>\n",
       "      <td>ILL @ NEB</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 00:00:00</td>\n",
       "      <td>Nebraska Cornhuskers</td>\n",
       "      <td>0</td>\n",
       "      <td>Illinois Fighting Illini</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401628492</td>\n",
       "      <td>Marshall Thundering Herd at Ohio State Buckeyes</td>\n",
       "      <td>MRSH @ OSU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 16:00:00</td>\n",
       "      <td>Ohio State Buckeyes</td>\n",
       "      <td>0</td>\n",
       "      <td>Marshall Thundering Herd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401635552</td>\n",
       "      <td>NC State Wolfpack at Clemson Tigers</td>\n",
       "      <td>NCSU @ CLEM</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 16:00:00</td>\n",
       "      <td>Clemson Tigers</td>\n",
       "      <td>0</td>\n",
       "      <td>NC State Wolfpack</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401636875</td>\n",
       "      <td>Arkansas State Red Wolves at Iowa State Cyclones</td>\n",
       "      <td>ARST @ ISU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 18:00:00</td>\n",
       "      <td>Iowa State Cyclones</td>\n",
       "      <td>0</td>\n",
       "      <td>Arkansas State Red Wolves</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401628493</td>\n",
       "      <td>Kent State Golden Flashes at Penn State Nittan...</td>\n",
       "      <td>KENT @ PSU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 19:30:00</td>\n",
       "      <td>Penn State Nittany Lions</td>\n",
       "      <td>0</td>\n",
       "      <td>Kent State Golden Flashes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>401628489</td>\n",
       "      <td>USC Trojans at Michigan Wolverines</td>\n",
       "      <td>USC @ MICH</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 19:30:00</td>\n",
       "      <td>Michigan Wolverines</td>\n",
       "      <td>0</td>\n",
       "      <td>USC Trojans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>401628365</td>\n",
       "      <td>UCLA Bruins at LSU Tigers</td>\n",
       "      <td>UCLA @ LSU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 19:30:00</td>\n",
       "      <td>LSU Tigers</td>\n",
       "      <td>0</td>\n",
       "      <td>UCLA Bruins</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>401628979</td>\n",
       "      <td>Miami (OH) RedHawks at Notre Dame Fighting Irish</td>\n",
       "      <td>M-OH @ ND</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 19:30:00</td>\n",
       "      <td>Notre Dame Fighting Irish</td>\n",
       "      <td>0</td>\n",
       "      <td>Miami (OH) RedHawks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>401635554</td>\n",
       "      <td>Georgia Tech Yellow Jackets at Louisville Card...</td>\n",
       "      <td>GT @ LOU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 19:30:00</td>\n",
       "      <td>Louisville Cardinals</td>\n",
       "      <td>0</td>\n",
       "      <td>Georgia Tech Yellow Jackets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>401644736</td>\n",
       "      <td>Buffalo Bulls at Northern Illinois Huskies</td>\n",
       "      <td>BUFF @ NIU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 19:30:00</td>\n",
       "      <td>Northern Illinois Huskies</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffalo Bulls</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>401636876</td>\n",
       "      <td>Utah Utes at Oklahoma State Cowboys</td>\n",
       "      <td>UTAH @ OKST</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 20:00:00</td>\n",
       "      <td>Oklahoma State Cowboys</td>\n",
       "      <td>0</td>\n",
       "      <td>Utah Utes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>401628368</td>\n",
       "      <td>Vanderbilt Commodores at Missouri Tigers</td>\n",
       "      <td>VAN @ MIZ</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 20:15:00</td>\n",
       "      <td>Missouri Tigers</td>\n",
       "      <td>0</td>\n",
       "      <td>Vanderbilt Commodores</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>401635555</td>\n",
       "      <td>Miami Hurricanes at South Florida Bulls</td>\n",
       "      <td>MIA @ USF</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 23:00:00</td>\n",
       "      <td>South Florida Bulls</td>\n",
       "      <td>0</td>\n",
       "      <td>Miami Hurricanes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>401628369</td>\n",
       "      <td>Tennessee Volunteers at Oklahoma Sooners</td>\n",
       "      <td>TENN @ OU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 23:30:00</td>\n",
       "      <td>Oklahoma Sooners</td>\n",
       "      <td>0</td>\n",
       "      <td>Tennessee Volunteers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>401628372</td>\n",
       "      <td>Bowling Green Falcons at Texas A&amp;M Aggies</td>\n",
       "      <td>BGSU @ TA&amp;M</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 23:30:00</td>\n",
       "      <td>Texas A&amp;M Aggies</td>\n",
       "      <td>0</td>\n",
       "      <td>Bowling Green Falcons</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>401628366</td>\n",
       "      <td>Georgia Southern Eagles at Ole Miss Rebels</td>\n",
       "      <td>GASO @ MISS</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-21 23:45:00</td>\n",
       "      <td>Ole Miss Rebels</td>\n",
       "      <td>0</td>\n",
       "      <td>Georgia Southern Eagles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>401628371</td>\n",
       "      <td>UL Monroe Warhawks at Texas Longhorns</td>\n",
       "      <td>ULM @ TEX</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-22 00:00:00</td>\n",
       "      <td>Texas Longhorns</td>\n",
       "      <td>0</td>\n",
       "      <td>UL Monroe Warhawks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>401636872</td>\n",
       "      <td>Kansas State Wildcats at BYU Cougars</td>\n",
       "      <td>KSU @ BYU</td>\n",
       "      <td>STATUS_SCHEDULED</td>\n",
       "      <td>2024-09-22 02:30:00</td>\n",
       "      <td>BYU Cougars</td>\n",
       "      <td>0</td>\n",
       "      <td>Kansas State Wildcats</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               name    shortName  \\\n",
       "0   401628485   Illinois Fighting Illini at Nebraska Cornhuskers    ILL @ NEB   \n",
       "1   401628492    Marshall Thundering Herd at Ohio State Buckeyes   MRSH @ OSU   \n",
       "2   401635552                NC State Wolfpack at Clemson Tigers  NCSU @ CLEM   \n",
       "3   401636875   Arkansas State Red Wolves at Iowa State Cyclones   ARST @ ISU   \n",
       "4   401628493  Kent State Golden Flashes at Penn State Nittan...   KENT @ PSU   \n",
       "5   401628489                 USC Trojans at Michigan Wolverines   USC @ MICH   \n",
       "6   401628365                          UCLA Bruins at LSU Tigers   UCLA @ LSU   \n",
       "7   401628979   Miami (OH) RedHawks at Notre Dame Fighting Irish    M-OH @ ND   \n",
       "8   401635554  Georgia Tech Yellow Jackets at Louisville Card...     GT @ LOU   \n",
       "9   401644736         Buffalo Bulls at Northern Illinois Huskies   BUFF @ NIU   \n",
       "10  401636876                Utah Utes at Oklahoma State Cowboys  UTAH @ OKST   \n",
       "11  401628368           Vanderbilt Commodores at Missouri Tigers    VAN @ MIZ   \n",
       "12  401635555            Miami Hurricanes at South Florida Bulls    MIA @ USF   \n",
       "13  401628369           Tennessee Volunteers at Oklahoma Sooners    TENN @ OU   \n",
       "14  401628372          Bowling Green Falcons at Texas A&M Aggies  BGSU @ TA&M   \n",
       "15  401628366         Georgia Southern Eagles at Ole Miss Rebels  GASO @ MISS   \n",
       "16  401628371              UL Monroe Warhawks at Texas Longhorns    ULM @ TEX   \n",
       "17  401636872               Kansas State Wildcats at BYU Cougars    KSU @ BYU   \n",
       "\n",
       "              status                date                   homeTeam  \\\n",
       "0   STATUS_SCHEDULED 2024-09-21 00:00:00       Nebraska Cornhuskers   \n",
       "1   STATUS_SCHEDULED 2024-09-21 16:00:00        Ohio State Buckeyes   \n",
       "2   STATUS_SCHEDULED 2024-09-21 16:00:00             Clemson Tigers   \n",
       "3   STATUS_SCHEDULED 2024-09-21 18:00:00        Iowa State Cyclones   \n",
       "4   STATUS_SCHEDULED 2024-09-21 19:30:00   Penn State Nittany Lions   \n",
       "5   STATUS_SCHEDULED 2024-09-21 19:30:00        Michigan Wolverines   \n",
       "6   STATUS_SCHEDULED 2024-09-21 19:30:00                 LSU Tigers   \n",
       "7   STATUS_SCHEDULED 2024-09-21 19:30:00  Notre Dame Fighting Irish   \n",
       "8   STATUS_SCHEDULED 2024-09-21 19:30:00       Louisville Cardinals   \n",
       "9   STATUS_SCHEDULED 2024-09-21 19:30:00  Northern Illinois Huskies   \n",
       "10  STATUS_SCHEDULED 2024-09-21 20:00:00     Oklahoma State Cowboys   \n",
       "11  STATUS_SCHEDULED 2024-09-21 20:15:00            Missouri Tigers   \n",
       "12  STATUS_SCHEDULED 2024-09-21 23:00:00        South Florida Bulls   \n",
       "13  STATUS_SCHEDULED 2024-09-21 23:30:00           Oklahoma Sooners   \n",
       "14  STATUS_SCHEDULED 2024-09-21 23:30:00           Texas A&M Aggies   \n",
       "15  STATUS_SCHEDULED 2024-09-21 23:45:00            Ole Miss Rebels   \n",
       "16  STATUS_SCHEDULED 2024-09-22 00:00:00            Texas Longhorns   \n",
       "17  STATUS_SCHEDULED 2024-09-22 02:30:00                BYU Cougars   \n",
       "\n",
       "    homeScore                     awayTeam  awayScore  \n",
       "0           0     Illinois Fighting Illini          0  \n",
       "1           0     Marshall Thundering Herd          0  \n",
       "2           0            NC State Wolfpack          0  \n",
       "3           0    Arkansas State Red Wolves          0  \n",
       "4           0    Kent State Golden Flashes          0  \n",
       "5           0                  USC Trojans          0  \n",
       "6           0                  UCLA Bruins          0  \n",
       "7           0          Miami (OH) RedHawks          0  \n",
       "8           0  Georgia Tech Yellow Jackets          0  \n",
       "9           0                Buffalo Bulls          0  \n",
       "10          0                    Utah Utes          0  \n",
       "11          0        Vanderbilt Commodores          0  \n",
       "12          0             Miami Hurricanes          0  \n",
       "13          0         Tennessee Volunteers          0  \n",
       "14          0        Bowling Green Falcons          0  \n",
       "15          0      Georgia Southern Eagles          0  \n",
       "16          0           UL Monroe Warhawks          0  \n",
       "17          0        Kansas State Wildcats          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2534424545119107,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Scrape scripts",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
